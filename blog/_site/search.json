[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Portafolio trabajos",
    "section": "",
    "text": "Métodos de optimización heurística\n\n\n\n\n\n\noptimización\n\n\nmétodos heurísticos\n\n\npython\n\n\n\n\n\n\n\n\n\nNov 15, 2024\n\n\nJulián Castaño Pineda, Luis Andrés Altamar Romero, Catalina Restrepo Salgado, Tomás Rodríguez Taborda\n\n\n\n\n\n\n\n\n\n\n\n\nWelcome To My Blog\n\n\n\n\n\n\nnews\n\n\n\n\n\n\n\n\n\nNov 12, 2024\n\n\nTristan O’Malley\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/post-with-code/index.html",
    "href": "posts/post-with-code/index.html",
    "title": "Métodos de optimización heurística",
    "section": "",
    "text": "Code\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits.mplot3d import Axes3D\nfrom matplotlib.animation import FuncAnimation\nfrom IPython.display import HTML\nfrom IPython.display import display\nfrom IPython.display import Image as IPImage\nimport io\nfrom PIL import Image\nEl objetivo de esta sección es evaluar diversos métodos de optimización aplicados a varias funciones, con el fin de medir su rendimiento. En particular, se utilizarán las funciones de Rosenbrock, Schwefel, Griewank, Goldstein-Price y la función de las seis jorobas de camello. Estas funciones serán optimizadas mediante el método del gradiente descendente y tres algoritmos heurísticos: Algoritmos Evolutivos, Optimización por Enjambre de Partículas y Evolución Diferencial.\nAl final, se comentará sobre los aportes de los métodos de descenso por gradiente y los métodos heurísticos, considerando el valor final de la función objetivo y el número de evaluaciones de la función objetivo, en un entorno de simulación con varios parámetros y condiciones para garantizar conclusiones significativas."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "This is the first post in a Quarto blog. Welcome!\n\nSince this post doesn’t specify an explicit image, the first image in the post will be used in the listing page of posts."
  },
  {
    "objectID": "posts/post-with-code/index.html#considere-las-siguientes-funciones-de-prueba",
    "href": "posts/post-with-code/index.html#considere-las-siguientes-funciones-de-prueba",
    "title": "Primer trabajo: Optimización heurística",
    "section": "",
    "text": "Función de Rosenbrock \\[ f(x, y) = (a - x)^2 + b(y - x^2)^2 \\]\nFunción de Rastrigin \\[ f(\\mathbf{x}) = An + \\sum_{i=1}^{n} \\left[ x_i^2 - A \\cos(2 \\pi x_i) \\right] \\]\nFunción de Schwefel \\[ f(\\mathbf{x}) = 418.9829n - \\sum_{i=1}^{n} x_i \\sin(\\sqrt{|x_i|}) \\]\nFunción de Griewank \\[ f(\\mathbf{x}) = 1 + \\frac{1}{4000} \\sum_{i=1}^{n} x_i^2 - \\prod_{i=1}^{n} \\cos\\left(\\frac{x_i}{\\sqrt{i}}\\right) \\]\nFunción Goldstein-Price \\[ f(x, y) = \\left[1 + (x + y + 1)^2 (19 - 14x + 3x^2 - 14y + 6xy + 3y^2)\\right] \\left[30 + (2x - 3y)^2 (18 - 32x + 12x^2 + 48y - 36xy + 27y^2)\\right] \\]\nFunción de las seis jorobas de camello \\[ f(x, y) = \\left(4 - 2.1x^2 + \\frac{x^4}{3}\\right)x^2 + xy + \\left(-4 + 4y^2\\right)y^2 \\]\n\n\n\n\nEscoja dos funciones de prueba.\nOptimización con método de descenso por gradiente:\n\nOptimice las funciones seleccionadas en dos y tres dimensiones usando un método de descenso por gradiente con condición inicial aleatoria.\n\nOptimización con métodos heurísticos:\n\nOptimice las funciones seleccionadas en dos y tres dimensiones usando:\n\nAlgoritmos evolutivos.\nOptimización de partículas.\nEvolución diferencial.\n\n\nRepresentación visual:\n\nCree un GIF animado o un video que muestre el proceso de optimización usando:\n\nDescenso por gradiente.\nMétodos heurísticos.\n\n\n\n\n\n\nReflexione sobre los siguientes puntos: - ¿Qué aportaron los métodos de descenso por gradiente y qué aportaron los métodos heurísticos? - Para responder a esta pregunta, considere: - El valor final de la función objetivo. - El número de evaluaciones de la función objetivo. - Es posible que se requiera realizar varias corridas de los algoritmos para obtener conclusiones significativas."
  },
  {
    "objectID": "posts/post-with-code/index.html#problema-del-viajero",
    "href": "posts/post-with-code/index.html#problema-del-viajero",
    "title": "Métodos de optimización heurística",
    "section": "5.1 Problema del Viajero:",
    "text": "5.1 Problema del Viajero:\nUn vendedor debe realizar un recorrido por todas las capitales de los 32 estados de los Estados Unidos Mexicanos.\n\n5.1.1 Tareas:\n\nOptimización con métodos metaheurísticos:\n\nUtilice colonias de hormigas para encontrar el orden óptimo del recorrido.\nUtilice algoritmos genéticos para encontrar el orden óptimo del recorrido.\n\nCosto del recorrido:\n\nEl costo de desplazamiento entre ciudades se calcula como la suma de:\n\nEl valor de la hora del vendedor (este es un parámetro que debe estudiarse).\nEl costo de los peajes.\nEl costo del combustible.\n\nCada equipo debe definir el vehículo que utilizará el vendedor para realizar el recorrido y, con base en esta elección, calcular el costo del combustible.\n\n\n\n\n5.1.2 Representación Visual:\n\nCree un GIF animado o un video que muestre cómo se comporta la mejor solución encontrada, usando un gráfico del recorrido en el mapa de México.\n\n\n\n\n5.1.3 Discusión:\nReflexione sobre: - Los resultados obtenidos con las colonias de hormigas y los algoritmos genéticos. - Comparación de costos y tiempo de ejecución."
  },
  {
    "objectID": "posts/post-with-code/index.html#funciones-a-optimizar",
    "href": "posts/post-with-code/index.html#funciones-a-optimizar",
    "title": "Primer trabajo: Optimización heurística",
    "section": "Funciones a optimizar",
    "text": "Funciones a optimizar\nSe seleccionaron seis funciones comúnmente empleadas para evaluar métodos de optimización, debido a sus características particulares. Estas funciones presentan desafíos como la existencia de un mínimo global acompañado de múltiples mínimos locales, así como valles que pueden dificultar la convergencia de los algoritmos. A continuación, se describen dichas funciones, incluyendo su forma funcional generalizada para \\(d\\) dimensiones, su representación gráfica en 2 dimensiones, el valor del mínimo global, una breve descripción de cada función y el rango de evaluación sugerido por diversos autores. Las gráficas fueron generadas a partir de la funcion plot_function() que se muestra en la pestaña de Code sugerida.\n\n\nCode\ndef plot_function(f, x1_range, x2_range, title=\"Function Plot\", x1_point=None, x2_point=None, elev=30, azim=45 ):\n    x1 = np.linspace(x1_range[0], x1_range[1], 400)\n    x2 = np.linspace(x2_range[0], x2_range[1], 400)\n    X1, X2 = np.meshgrid(x1, x2)\n    Z = f(np.array([X1,X2]))\n\n    fig = plt.figure(figsize=(8, 4))\n\n    # 3D plot\n    ax1 = fig.add_subplot(121, projection='3d')\n    ax1.plot_surface(X1, X2, Z)\n    ax1.set_title(f'3D Plot of {title}')\n    ax1.set_xlabel('X1')\n    ax1.set_ylabel('X2')\n    ax1.set_zlabel('Z')\n\n    ax1.view_init(elev=elev, azim=azim)\n\n    if x1_point is not None and x2_point is not None:\n        z_point = f(np.array([x1_point, x2_point])[:, None, None])[0, 0]\n\n        ax1.plot([x1_point], [x2_point], [z_point], color='r', marker='o', markersize=5, linewidth=0, label=\"Mínimo global\", zorder=5)\n        ax1.legend()\n\n    # Contour plot\n    ax2 = fig.add_subplot(122)\n    contour = ax2.contour(X1, X2, Z, levels = 10)\n    ax2.set_title(f'Contour Plot of {title}')\n    ax2.set_xlabel('X1')\n    ax2.set_ylabel('X2')\n    fig.colorbar(contour, ax=ax2)\n\n    if x1_point is not None and x2_point is not None:\n        ax2.plot([x1_point], [x2_point], color='r', marker='o', markersize=5, linewidth=0, label=\"Mínimo global\", zorder=5)\n        ax2.legend()\n\n    plt.show()\n\n\n\nFunción de RosenbrockFunción de RastriginFunción de SchwefelFunción de GriewankFunción Goldstein-PriceFunción de las seis jorobas de camello\n\n\n\\[f(\\mathbf{x}) = \\sum_{i=1}^{d-1} \\left[ 100(x_{i+1} - x_i^2)^2 + (x_i - 1)^2 \\right]\\]\n\n\nCode\n# Función de Rosenbrock\ndef rosenbrock(x, a=1, b=100):\n    \"\"\"\n    Calcula el valor de la función de Rosenbrock.\n    x: vector de entrada (numpy array)\n    a, b: parámetros de la función\n    \"\"\"\n    return (sum(b * (x[1:] - x[:-1]**2)**2 + (x[:-1] - a)**2))\n\nplot_function(rosenbrock, x1_range=(-2.048, 2.048), x2_range=(-2.048, 2.048), title=\"Función Rosenbrock\", x1_point=1, x2_point=1)\n\n\n\n\n\n\n\n\n\nEn 2 dimensiones se puede definir como \\[ f(x_1, x_2) = (a - x_1)^2 + b(x_2 - x_1^2)^2 \\]\nLa Función de Rosenbrock, también conocida como función del valle o del plátano, es ampliamente utilizada para evaluar algoritmos de optimización basados en gradientes. Esta función es unimodal y presenta su mínimo global en un valle parabólico estrecho, lo que facilita su localización. Sin embargo, segun Simon Fraser University (n.d.) citando a Picheny, Wagner, and Ginsbourger (2012) convergencia hacia este mínimo puede ser desafiante debido a la naturaleza del valle.\nLa función se evalúa generalmente en el hipercubo \\(x_i \\in [-5, 10]\\) y tiene un mínimo global en \\(f(1,...,1) = 0\\)\n\n\n\\[f(\\mathbf{x}) = 10d + \\sum_{i=1}^{d} \\left[ x_i^2 - 10 \\cos(2\\pi x_i) \\right]\\]\n\n\nCode\n# Función de Rastrigin\ndef rastrigin(x):\n    \"\"\"\n    Calcula el valor de la función de Rastrigin.\n    x: vector de entrada (numpy array)\n    \"\"\"\n    d = len(x)\n    return 10 * d + sum(x**2 - 10 * np.cos(2 * np.pi * x))\nplot_function(rastrigin, x1_range=(-5.12, 5.12), x2_range=(-5.12, 5.12), title=\"Función Rastrigin\", x1_point=0, x2_point=0)\n\n\n\n\n\n\n\n\n\nSegun Simon Fraser University (n.d.), la función de Rastrigin tiene varios mínimos locales. Es altamente multimodal, pero las ubicaciones de los mínimos se distribuyen regularmente. La función generalmente se evalúa en el hipercubo \\(x_i \\in [-5.12, 5.12]\\) y su mínimo local se encuentra en \\(f(0,...,0)=0\\).\n\n\n\\[ f(\\mathbf{x}) = 418.9829d - \\sum_{i=1}^{d} x_i \\sin(\\sqrt{|x_i|}) \\]\n\n\nCode\n# Función de Schwefel\ndef schwefel(x):\n    \"\"\"\n    Calcula el valor de la función de Schwefel.\n    x: vector de entrada (numpy array)\n    \"\"\"\n    d = len(x)\n    return 418.9829 * d - sum(x * np.sin(np.sqrt(np.abs(x))))\nplot_function(schwefel, x1_range=(-500, 500), x2_range=(-500, 500), title=\"Función Schwefel\", x1_point=420.9687, x2_point=420.9687)\n\n\n\n\n\n\n\n\n\nSegun Simon Fraser University (n.d.) La función de Schwefel es compleja, con muchos mínimos locales. Normalmente se evalua en el hipercubo \\(x_i \\in [-500,500]\\). Su minimo global está en \\(f(420.9687,...,420.9687)=0\\)\n\n\n\\[ f(\\mathbf{x}) = 1 + \\frac{1}{4000} \\sum_{i=1}^{d} x_i^2 - \\prod_{i=1}^{d} \\cos\\left(\\frac{x_i}{\\sqrt{i}}\\right) \\]\n\n\nCode\n# Función de Griewank\ndef griewank(x):\n    \"\"\"\n    Calcula el valor de la función Griewank.\n    x: numpy array unidimensional (1D) o un array con forma (d, n1, n2) para evaluaciones vectorizadas.\n    \n    Retorna:\n    - Un valor escalar si `x` es 1D.\n    - Una matriz (n1, n2) si `x` tiene forma (d, n1, n2).\n    \"\"\"\n    x = np.asarray(x)\n\n    if x.ndim == 1:\n        # Caso 1D: calcular para un solo vector\n        d = len(x)\n        sum_term = np.sum(x**2) / 4000\n        product_term = np.prod(np.cos(x / np.sqrt(np.arange(1, d + 1))))\n        return 1 + sum_term - product_term\n\n    elif x.ndim == 3:\n        # Caso ND: calcular para una cuadrícula (vectorizado)\n        d = x.shape[0]\n        i_indices = np.arange(1, d + 1).reshape(-1, 1, 1)\n        sum_term = np.sum(x**2, axis=0) / 4000\n        product_term = np.prod(np.cos(x / np.sqrt(i_indices)), axis=0)\n        return 1 + sum_term - product_term\n\n    else:\n        raise ValueError(\"La entrada debe ser un array 1D o un array con forma (d, n1, n2).\")\nplot_function(griewank, x1_range=(-600, 600), x2_range=(-600, 600), title=\"Función Griewank\", x1_point=0, x2_point=0)\n\n\n\n\n\n\n\n\n\nSegun Simon Fraser University (n.d.) la función de Griewank tiene muchos mínimos locales generalizados, que se distribuyen de forma regular. Lo que hace compleja su optimización al minimo global. Normalmente se evalua en el hipercubo \\(x_i \\in [-600,600]\\). Su minimo global está en \\(f(0,...,0)=0\\)\n\n\n\\[\n\\begin{align}\nf(x_1, x_2) = & \\left[1 + (x_1 + x_2 + 1)^2 (19 - 14x_1 + 3x_1^2 - 14x_2 + 6x_1x_2 + 3x_2^2)\\right] \\\\\n         & \\left[30 + (2x_1 - 3x_2)^2 (18 - 32x_1 + 12x_1^2 + 48x_2 - 36x_1x_2 + 27x_2^2)\\right]\n\\end{align}\n\\]\n\n\nCode\n# Función Goldstein-Price\ndef goldstein_price(x):\n    \"\"\"\n    Calcula el valor de la función Goldstein-Price.\n    x1, x2: coordenadas en 2D\n    \"\"\"\n    x1=x[0]\n    x2=x[1]\n    term1 = (1 + (x1 + x2 + 1)**2 * (19 - 14 * x1 + 3 * x1**2 - 14 * x2 + 6 * x1 * x2 + 3 * x2**2))\n    term2 = (30 + (2 * x1 - 3 * x2)**2 * (18 - 32 * x1 + 12 * x1**2 + 48 * x2 - 36 * x1 * x2 + 27 * x2**2))\n    return term1 * term2\nplot_function(goldstein_price, x1_range=(-2, 2), x2_range=(-2, 2), title=\"Función Goldstein price\", x1_point=0, x2_point=-1)\n\n\n\n\n\n\n\n\n\nLa función Goldstein-Price es una función en 2 dimensiones y tiene varios mínimos locales. Segun Molga and Smutnicki (2005), la función generalmente se evalúa en el cuadrado \\(x_1 \\in [-2, 2]\\) y \\(x_1 \\in [-2, 2]\\) . Su mínimo global es \\(f(0,-1) = 3\\)\n\n\n\\[ f(x_1, x_2) = \\left(4 - 2.1x_1^2 + \\frac{x_1^4}{3}\\right)x_1^2 + x_1x_2 + \\left(-4 + 4x_2^2\\right)x_2^2 \\]\n\n\nCode\n# Función de las seis jorobas de camello\ndef camel_six_humps(x):\n    \"\"\"\n    Calcula el valor de la función de las seis jorobas de camello.\n    x1, x2: coordenadas en 2D\n    \"\"\"\n    x1 = x[0]\n    x2 = x[1]\n    term1 = (4 - 2.1 * x1**2 + x1**4 / 3) * x1**2\n    term2 = x1 * x2\n    term3 = (-4 + 4 * x2**2) * x2**2\n    return term1 + term2 + term3\nplot_function(camel_six_humps, x1_range=(-2, 2), x2_range=(-1, 1), title=\"Función 6 jorobas de camello\", x1_point=0.0898, x2_point=-0.7126, elev=30, azim=75 )\n\n\n\n\n\n\n\n\n\nLa función de las seis jorobas de camello es una función en 2 dimensiones.Segun Molga and Smutnicki (2005) la función tiene seis mínimos locales, dos de los cuales son globales y recomienda evaluar la función en el rectángulo \\(x_1 \\in [-3, 3], x_2 \\in [-2, 2]\\), donde los mínimos globales son \\(f(0.0898,-0.7126) = -1.0316\\) y \\(f(-0.0898, 0.7126) = -1.0316\\)"
  },
  {
    "objectID": "posts/post-with-code/index.html#proceso-de-optimización",
    "href": "posts/post-with-code/index.html#proceso-de-optimización",
    "title": "Primer trabajo: Optimización heurística",
    "section": "Proceso de optimización",
    "text": "Proceso de optimización\n\nOptimización por descenso del gradiente\nEl descenso del gradiente es un algoritmo de optimización iterativo que busca encontrar el mínimo local de una función diferenciable. La idea principal es moverse en la dirección opuesta al gradiente de la función en cada punto, ya que el gradiente apunta en la dirección de máximo crecimiento.\nSegun (Bishop 2006), para una función \\(f(x)\\), el algoritmo actualiza iterativamente el punto \\(x\\) usando la regla:\n\\[ x_{t+1} = x_t - \\eta \\nabla f(x_t) \\]\ndonde:\n\n\\(x_t\\) es el punto actual\n\\(\\eta\\) es la tasa de aprendizaje\n\\(\\nabla f(x_t)\\) es el gradiente de la función en \\(x_t\\)\n\nEl gradiente \\(\\nabla f\\) es un vector que contiene las derivadas parciales respecto a cada variable: \\[\\nabla f(x_1, x_2) = \\begin{bmatrix} \\frac{\\partial f}{\\partial x_1}, \\frac{\\partial f}{\\partial x_2} \\end{bmatrix}\\]\nEl gradiente \\(\\nabla f\\) se puede aproximar numéricamente usando diferencias finitas. (Bishop 2006) plantean que, se puede mejorar consideramblemente la presición del método usando diferencias centrales simétricas. En este caso, para una función \\(f(x_1, x_2)\\), las derivadas parciales se calculan como:\n\\[ \\frac{\\partial f}{\\partial x_1} \\approx \\frac{f(x_1 + h, x_2) - f(x_1 - h, x_2)}{2h} \\]\n\\[ \\frac{\\partial f}{\\partial x_2} \\approx \\frac{f(x_1, x_2 + h) - f(x_1, x_2 - h)}{2h} \\]\ndonde \\(h\\) es un pequeño incremento (típicamente \\(10^{-7}\\) o \\(10^{-8}\\)).\n\n\nCode\ndef partial_derivative(x0, func, i, h, *args):\n  e = np.zeros(len(x0))\n  e[i] = 1\n  return (func(x0+h*e, *args) - func(x0-h*e, *args))/(2*h)\n\ndef numerical_gradient(x0, func, h, *args):\n  gradient = np.zeros(len(x0))\n  for i in range(len(x0)):\n    gradient[i] = partial_derivative(x0, func, i, h, *args)\n  return gradient\n\ndef gradient_descent_num_dev_mult(x0, eta, func, h, max_iter, *args):\n  \"\"\"\n  Perform gradient descent with numerical derivatives for a multi-dimensional function.\n\n  Parameters:\n      x0 (array-like): Initial guess for the variables.\n      eta (float): Learning rate.\n      func (callable): Function to minimize.\n      h (float): Step size for numerical gradient calculation.\n      max_iter (int): Maximum number of iterations.\n      *args: Additional arguments for the function.\n\n  Returns:\n      result_df (pd.DataFrame): DataFrame with columns ['x1', 'x2', 'f(x1,x2)']\n                                containing the trajectory of points.\n  \"\"\"\n  x_old = np.array(x0)\n  x_hist = []  # List to store the history of x and f(x)\n\n  for i in range(max_iter):\n      # Calculate the gradient numerically\n      gradient = numerical_gradient(x_old, func, h, *args)\n\n      # Update x based on gradient descent rule\n      x_new = x_old - eta * gradient\n\n      # Append current x and function value to history\n      x_hist.append([x_old[0], x_old[1], func(x_old, *args)])\n\n      # Update x_old\n      x_old = x_new\n\n  # Add the final position and function value\n  x_hist.append([x_new[0], x_new[1], func(x_new, *args)])\n\n  # Convert history to a pandas DataFrame\n  result_df = pd.DataFrame(x_hist, columns=['x1', 'x2', 'f(x1,x2)'])\n\n  return result_df\n\n\nA continuación, se presentan las animaciones que ilustran la aplicación del descenso del gradiente en las seis funciones evaluadas. Los parámetros iniciales, la tasa de aprendizaje y el número de iteraciones del algoritmo fueron seleccionados cuidadosamente para optimizar la visualización del funcionamiento del método.Estos parámetros se detallan en las tablas a continuación.\n\nFunción de RosenbrockFunción de RastriginFunción de SchwefelFunción de GriewankFunción Goldstein-PriceFunción de las seis jorobas de camello\n\n\n\\[f(\\mathbf{x}) = \\sum_{i=1}^{d-1} \\left[ 100(x_{i+1} - x_i^2)^2 + (x_i - 1)^2 \\right]\\]\n\n\n\n\\(x_{1_0}\\)\n\\(x_{2_0}\\)\n\\(\\eta\\)\n\\(n\\)\n\n\n\n\n-1.5\n-1.7\n0.001\n30\n\n\n\n\n\n\n\\[f(\\mathbf{x}) = 10d + \\sum_{i=1}^{d} \\left[ x_i^2 - 10 \\cos(2\\pi x_i) \\right]\\]\n\n\n\n\\(x_{1_0}\\)\n\\(x_{2_0}\\)\n\\(\\eta\\)\n\\(n\\)\n\n\n\n\n-0.46\n0.46\n0.005\n30\n\n\n\n\n\n\n\\[ f(\\mathbf{x}) = 418.9829d - \\sum_{i=1}^{d} x_i \\sin(\\sqrt{|x_i|}) \\]\n\n\n\n\\(x_{1_0}\\)\n\\(x_{2_0}\\)\n\\(\\eta\\)\n\\(n\\)\n\n\n\n\n310\n310\n0.8\n30\n\n\n\n\n\n\n\\[ f(\\mathbf{x}) = 1 + \\frac{1}{4000} \\sum_{i=1}^{d} x_i^2 - \\prod_{i=1}^{d} \\cos\\left(\\frac{x_i}{\\sqrt{i}}\\right) \\]\n\n\n\n\\(x_{1_0}\\)\n\\(x_{2_0}\\)\n\\(\\eta\\)\n\\(n\\)\n\n\n\n\n-500\n500\n70\n33\n\n\n\n\n\n\n\\[\n\\begin{align}\nf(x_1, x_2) = & \\left[1 + (x_1 + x_2 + 1)^2 (19 - 14x_1 + 3x_1^2 - 14x_2 + 6x_1x_2 + 3x_2^2)\\right] \\\\\n         & \\left[30 + (2x_1 - 3x_2)^2 (18 - 32x_1 + 12x_1^2 + 48x_2 - 36x_1x_2 + 27x_2^2)\\right]\n\\end{align}\n\\]\n\n\n\n\\(x_{1_0}\\)\n\\(x_{2_0}\\)\n\\(\\eta\\)\n\\(n\\)\n\n\n\n\n0.5\n-1.5\n0.00005\n50\n\n\n\n\n\n\n\\[ f(x_1, x_2) = \\left(4 - 2.1x_1^2 + \\frac{x_1^4}{3}\\right)x_1^2 + x_1x_2 + \\left(-4 + 4x_2^2\\right)x_2^2 \\]\n\n\n\n\\(x_{1_0}\\)\n\\(x_{2_0}\\)\n\\(\\eta\\)\n\\(n\\)\n\n\n\n\n-1\n-1\n0.015\n33\n\n\n\n\n\n\n\nEl método del gradiente descendente puede imaginarse como una persona deslizándose por una colina representada por una función. El punto de inicio es el lugar desde donde comienza a deslizarse, y la tasa de aprendizaje actúa como la aceleración que controla la velocidad del deslizamiento en cada paso. Si esta aceleración es demasiado alta, puede ayudar a llegar más rápido al valle más bajo, pero también existe el riesgo de salir del camino o incluso terminar subiendo una colina debido a un impulso excesivo que sobrepasa el objetivo.\nPara garantizar que este método sea eficiente, es importante considerar lo siguiente:\n\nTasa de aprendizaje: Un valor demasiado grande puede causar divergencia, mientras que uno muy pequeño puede hacer que el proceso sea extremadamente lento.\nPunto inicial: La ubicación inicial afecta la trayectoria y la probabilidad de alcanzar el mínimo global.\nCriterio de parada: Es esencial definir cuándo detener el algoritmo, ya sea por alcanzar un número máximo de iteraciones o porque la mejora entre pasos sea insignificante (convergencia)."
  },
  {
    "objectID": "posts/post-with-code/funciones.html",
    "href": "posts/post-with-code/funciones.html",
    "title": "",
    "section": "",
    "text": "CodeShow All CodeHide All Code\n\n\n\n\n\n\nCode\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits.mplot3d import Axes3D\n\n\nMatplotlib is building the font cache; this may take a moment.\n\n\n\n\nCode\nimport numpy as np\n\n# Función de Rosenbrock\ndef rosenbrock(x1, x2, a=1, b=100):\n    return (a - x1)**2 + b * (x2 - x1**2)**2\n\n# Función de Schwefel\ndef schwefel(x1, x2):\n    return 418.9829 * 2 - (x1 * np.sin(np.sqrt(np.abs(x1))) + x2 * np.sin(np.sqrt(np.abs(x2))))\n\n# Función de Griewank\ndef griewank(x1, x2):\n    return 1 + (x1**2 + x2**2) / 4000 - (np.cos(x1 / np.sqrt(1)) * np.cos(x2 / np.sqrt(2)))\n\n# Función Goldstein-Price\ndef goldstein_price(x1, x2):\n    term1 = 1 + (x1 + x2 + 1)**2 * (19 - 14*x1 + 3*x1**2 - 14*x2 + 6*x1*x2 + 3*x2**2)\n    term2 = 30 + (2*x1 - 3*x2)**2 * (18 - 32*x1 + 12*x1**2 + 48*x2 - 36*x1*x2 + 27*x2**2)\n    return term1 * term2\n\n# Función de las seis jorobas de camello\ndef six_hump_camel(x1, x2):\n    return (4 - 2.1*x1**2 + (x1**4) / 3) * x1**2 + x1 * x2 + (-4 + 4*x2**2) * x2**2\n\n\n\n\nCode\ndef plot_function(f, x1_range, x2_range, title=\"Function Plot\"):\n    x1 = np.linspace(x1_range[0], x1_range[1], 400)\n    x2 = np.linspace(x2_range[0], x2_range[1], 400)\n    X1, X2 = np.meshgrid(x1, x2)\n    Z = f(X1, X2)\n\n    fig = plt.figure(figsize=(14, 6))\n\n    # 3D plot\n    ax1 = fig.add_subplot(121, projection='3d')\n    ax1.plot_surface(X1, X2, Z)\n    ax1.set_title(f'3D Plot of {title}')\n    ax1.set_xlabel('X1')\n    ax1.set_ylabel('X2')\n    ax1.set_zlabel('Z')\n\n    # Contour plot\n    ax2 = fig.add_subplot(122)\n    contour = ax2.contour(X1, X2, Z)\n    ax2.set_title(f'Contour Plot of {title}')\n    ax2.set_xlabel('X1')\n    ax2.set_ylabel('X2')\n    fig.colorbar(contour, ax=ax2)\n\n    plt.show()\n\ndef plot_function(f, x1_range, x2_range, title=\"Function Plot\", x1_point=None, x2_point=None):\n    x1 = np.linspace(x1_range[0], x1_range[1], 400)\n    x2 = np.linspace(x2_range[0], x2_range[1], 400)\n    X1, X2 = np.meshgrid(x1, x2)\n    Z = f(X1, X2)\n\n    fig = plt.figure(figsize=(14, 6))\n\n    # 3D plot\n    ax1 = fig.add_subplot(121, projection='3d')\n    ax1.plot_surface(X1, X2, Z)\n    ax1.set_title(f'3D Plot of {title}')\n    ax1.set_xlabel('X1')\n    ax1.set_ylabel('X2')\n    ax1.set_zlabel('Z')\n\n    if x1_point is not None and x2_point is not None:\n        z_point = f(x1_point, x2_point)\n        ax1.scatter(x1_point, x2_point, z_point+1, color='red', s=50)\n\n    # Contour plot\n    ax2 = fig.add_subplot(122)\n    contour = ax2.contour(X1, X2, Z, cmap='viridis')\n    ax2.set_title(f'Contour Plot of {title}')\n    ax2.set_xlabel('X1')\n    ax2.set_ylabel('X2')\n    fig.colorbar(contour, ax=ax2)\n\n    if x1_point is not None and x2_point is not None:\n        ax2.scatter(x1_point, x2_point, color='red', s=50)\n\n    plt.show()\n\n# Ejemplo de uso con la función de Rosenbrock\ndef rosenbrock(x1, x2, a=1, b=100):\n    return (a - x1)**2 + b * (x2 - x1**2)**2\n\nplot_function(rosenbrock, x1_range=(-2, 2), x2_range=(-1, 3), title=\"Rosenbrock Function\", x1_point=-1, x2_point=1)\n\n\n\n\n\n\n\n\n\n\n\n\nCode\n\n\ndef plot_function(f, x1_range, x2_range, title=\"Function Plot\", x1_point=None, x2_point=None):\n    x1 = np.linspace(x1_range[0], x1_range[1], 400)\n    x2 = np.linspace(x2_range[0], x2_range[1], 400)\n    X1, X2 = np.meshgrid(x1, x2)\n    Z = f(X1, X2)\n\n    fig = plt.figure(figsize=(14, 6))\n\n    \n    # 3D plot\n    ax1 = fig.add_subplot(121, projection='3d')\n    if x1_point is not None and x2_point is not None:\n        z_point = f(x1_point, x2_point)\n        ax1.scatter(x1_point, x2_point, z_point, color='red', s=50, depthshade=False)  # Ajuste pequeño\n    ax1.plot_surface(X1, X2, Z, cmap='viridis', alpha=0.7)\n    ax1.set_title(f'3D Plot of {title}')\n    ax1.set_xlabel('X1')\n    ax1.set_ylabel('X2')\n    ax1.set_zlabel('Z')\n\n   \n\n    # Contour plot\n    ax2 = fig.add_subplot(122)\n    contour = ax2.contour(X1, X2, Z, cmap='viridis')\n    ax2.set_title(f'Contour Plot of {title}')\n    ax2.set_xlabel('X1')\n    ax2.set_ylabel('X2')\n    fig.colorbar(contour, ax=ax2)\n\n    if x1_point is not None and x2_point is not None:\n        ax2.scatter(x1_point, x2_point, color='red', s=50)\n\n    plt.show()\n\n# Ejemplo de uso con la función de Rosenbrock\ndef rosenbrock(x1, x2, a=1, b=100):\n    return (a - x1)**2 + b * (x2 - x1**2)**2\n\nplot_function(rosenbrock, x1_range=(-2, 2), x2_range=(-1, 3), title=\"Rosenbrock Function\", x1_point=-1, x2_point=1)\n\n\n\n\n\n\n\n\n\n\n\nCode\ndef plot_function(f, x1_range, x2_range, title=\"Function Plot\", x1_point=None, x2_point=None):\n    x1 = np.linspace(x1_range[0], x1_range[1], 400)\n    x2 = np.linspace(x2_range[0], x2_range[1], 400)\n    X1, X2 = np.meshgrid(x1, x2)\n    Z = f(X1, X2)\n\n    fig = plt.figure(figsize=(14, 6))\n\n    # 3D plot\n    ax1 = fig.add_subplot(121, projection='3d')\n    # Primero dibujamos la superficie\n    surface = ax1.plot_surface(X1, X2, Z, cmap='viridis', alpha=0.7)\n    \n    # Luego dibujamos el punto\n    if x1_point is not None and x2_point is not None:\n        z_point = f(x1_point, x2_point)\n        ax1.scatter(x1_point, x2_point, z_point, color='red', s=100, depthshade=False, linewidth=2, edgecolor='black')\n    \n    ax1.set_title(f'3D Plot of {title}')\n    ax1.set_xlabel('X1')\n    ax1.set_ylabel('X2')\n    ax1.set_zlabel('Z')\n\n\n\n\nCode\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nimport numpy as np\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\n\ndef plot_function_3d(f, x1_range, x2_range, title=\"Function Plot\", x1_point=None, x2_point=None):\n    # Create the mesh grid\n    x1 = np.linspace(x1_range[0], x1_range[1], 100)\n    x2 = np.linspace(x2_range[0], x2_range[1], 100)\n    X1, X2 = np.meshgrid(x1, x2)\n    Z = f(X1, X2)\n    \n    # Create subplots\n    fig = make_subplots(\n        rows=1, cols=2,\n        specs=[[{'type': 'surface'}, {'type': 'contour'}]],\n        subplot_titles=('3D Surface Plot', 'Contour Plot')\n    )\n    \n    # Add surface plot\n    fig.add_trace(\n        go.Surface(x=X1, y=X2, z=Z, colorscale='viridis', opacity=0.8),\n        row=1, col=1\n    )\n    \n    # Add point if specified\n    if x1_point is not None and x2_point is not None:\n        z_point = f(x1_point, x2_point)\n        fig.add_trace(\n            go.Scatter3d(\n                x=[x1_point],\n                y=[x2_point],\n                z=[z_point],\n                mode='markers',\n                marker=dict(size=8, color='red'),\n                name='Point'\n            ),\n            row=1, col=1\n        )\n    \n    # Add contour plot\n    fig.add_trace(\n        go.Contour(\n            x=x1,\n            y=x2,\n            z=Z,\n            colorscale='viridis'\n        ),\n        row=1, col=2\n    )\n    \n    # Update layout\n    fig.update_layout(\n        title=title,\n        width=1200,\n        height=500,\n        scene=dict(\n            xaxis_title='X1',\n            yaxis_title='X2',\n            zaxis_title='Z'\n        )\n    )\n    \n    fig.show()\n\n# Test the function\ndef rosenbrock(x1, x2, a=1, b=100):\n    return (a - x1)**2 + b * (x2 - x1**2)**2\n\nplot_function_3d(rosenbrock, (-2, 2), (-1, 3), \"Rosenbrock Function\", x1_point=-1, x2_point=1)\n\nplot_function(rosenbrock, x1_range=(-5, 5), x2_range=(-5, 15), title=\"Rosenbrock Function\",x1_point=-1, x2_point=1)\n\n\n\n---------------------------------------------------------------------------\nModuleNotFoundError                       Traceback (most recent call last)\nCell In[64], line 2\n      1 import numpy as np\n----&gt; 2 import plotly.graph_objects as go\n      3 from plotly.subplots import make_subplots\n      5 def plot_function_3d(f, x1_range, x2_range, title=\"Function Plot\", x1_point=None, x2_point=None):\n      6     # Create the mesh grid\n\nModuleNotFoundError: No module named 'plotly'"
  },
  {
    "objectID": "posts/post-with-code/index.html#resultados",
    "href": "posts/post-with-code/index.html#resultados",
    "title": "Primer trabajo: Optimización heurística",
    "section": "Resultados",
    "text": "Resultados"
  },
  {
    "objectID": "posts/post-with-code/index.html#conclusiones-y-comentarios",
    "href": "posts/post-with-code/index.html#conclusiones-y-comentarios",
    "title": "Primer trabajo: Optimización heurística",
    "section": "Conclusiones y comentarios",
    "text": "Conclusiones y comentarios\n\nTareas:\n\nEscoja dos funciones de prueba.\nOptimización con método de descenso por gradiente:\n\nOptimice las funciones seleccionadas en dos y tres dimensiones usando un método de descenso por gradiente con condición inicial aleatoria.\n\nOptimización con métodos heurísticos:\n\nOptimice las funciones seleccionadas en dos y tres dimensiones usando:\n\nAlgoritmos evolutivos.\nOptimización de partículas.\nEvolución diferencial.\n\n\nRepresentación visual:\n\nCree un GIF animado o un video que muestre el proceso de optimización usando:\n\nDescenso por gradiente.\nMétodos heurísticos.\n\n\n\n\n\nDiscusión:\nReflexione sobre los siguientes puntos: - ¿Qué aportaron los métodos de descenso por gradiente y qué aportaron los métodos heurísticos? - Para responder a esta pregunta, considere: - El valor final de la función objetivo. - El número de evaluaciones de la función objetivo. - Es posible que se requiera realizar varias corridas de los algoritmos para obtener conclusiones significativas."
  },
  {
    "objectID": "posts/post-with-code/index.html#agoritmo-genético",
    "href": "posts/post-with-code/index.html#agoritmo-genético",
    "title": "Métodos de optimización heurística",
    "section": "2.2 Agoritmo genético",
    "text": "2.2 Agoritmo genético\nUn algoritmo genético (GA) es un método heurístico de optimización inspirado en los principios de la selección natural y la evolución biológica, propuesto inicialmente por (Holland 1975). Este enfoque busca soluciones óptimas en un espacio de búsqueda utilizando una población de candidatos.\n\n2.2.1 Concepto General\nEl algoritmo genético simula el proceso evolutivo a través de las siguientes etapas:\n\nSelección: Elegir individuos con mayor fitness.1\nCruce: Combinar soluciones para generar descendencia.\nMutación: Introducir variación genética.\n\nMatemáticamente, en un problema de minimización, el objetivo es encontrar:\n\\[ x^* = \\arg\\min_{x \\in \\mathbb{R}^n} f(x) \\]\ndonde:\n\n\\(x\\) representa un individuo en el espacio de búsqueda.\n\\(f(x)\\) es la función objetivo que evalúa la calidad de \\(x\\).\n\nCada solución candidata se representa como un individuo, que puede ser un vector real o un cromosoma binario:\n\\[x = (x_1, x_2, \\ldots, x_n) \\in \\mathbb{R}^n\\]\nLa función objetivo mide qué tan buena es una solución:\n\\[\\text{Fitness}(x) = f(x)\\]\nPara problemas de minimización, menor \\(f(x)\\) implica mejor fitness.\n\n\n\n2.2.2 Etapas\nInicialización de la Población\nSe genera una población inicial de \\(P\\) individuos de forma aleatoria dentro de un intervalo \\([a, b]\\) :\n\\[x_{ij} \\sim \\text{U}(a, b), \\quad \\forall i \\in \\{1, 2, \\ldots, P\\}, \\; j \\in \\{1, 2, \\ldots, n\\}\\] donde:\n\n\\(x_{ij}\\) es la \\(j-ésima\\) coordenada del \\(i-ésimo\\) individuo.\n\n\n\nCode\n# Inicializar población\ndef initialize_population(size, dim, bounds):\n    return np.random.uniform(bounds[0], bounds[1], (size, dim))\n\n\n\nEvaluación del Fitness\nCada individuo de la población es evaluado usando la función objetivo:\n\\(\\text{Fitness}_i = f(x_i)\\)\n\n\nCode\n# Evaluar fitness\ndef evaluate_fitness(population,fitness_function):\n    return np.array([fitness_function(ind) for ind in population])\n\n\n\nSelección\nSe seleccionan individuos para reproducirse basándose en su fitness. Un métodos comune es el método de torneo, donde primero se seleccionan \\(k\\) individuos al azar y luego se elige al mejor de ellos(mejor fitness):\n\\[\\text{Individuo seleccionado} = \\arg\\min_{j \\in S} \\text{Fitness}_j, \\; S \\subseteq \\{1, \\ldots, P\\}, \\; |S| = k\\]\n\n\nCode\n# Selección por torneo\ndef tournament_selection(population, fitness, k=3):\n    selected = []\n    for _ in range(len(population)):\n        candidates = np.random.choice(range(len(population)), k, replace=False)\n        winner = candidates[np.argmin(fitness[candidates])]\n        selected.append(population[winner])\n    return np.array(selected)\n\n\n\nCruce (Recombinación)\nDos individuos (padres) se combinan para generar descendencia. Un método común es punto de corte único, donde: 1. Se Elegie un punto de cruce aleatorio \\(k\\). 2. Se genera la descendencia mezclando las características de los padres.\n\\[\\text{Hijo 1} = (\\text{Padre}_1[:k], \\text{Padre}_2[k:])\\]\n\\[\\text{Hijo 2} = (\\text{Padre}_2[:k], \\text{Padre}_1[k:])\\]\nLa probabilidad de realizar un cruce está determinada por \\(p_c\\) (tasa de cruce).\n\n\nCode\n# Cruce\ndef crossover(parent1, parent2, crossover_rate):\n    if np.random.rand() &lt; crossover_rate:\n        point = np.random.randint(1, len(parent1))\n        child = np.concatenate([parent1[:point], parent2[point:]])\n        return child\n    return parent1 if np.random.rand() &lt; 0.5 else parent2\n\n\n\nMutación\nSe introduce una variación genética al modificar aleatoriamente uno o más genes(variables) en un individuo(punto del plano) con probabilidad \\(p_m\\):\n\\[x_{ij} = x_{ij} + \\Delta, \\quad \\Delta \\sim \\text{U}(-\\delta, \\delta)\\]\ndonde:\n\n\\(\\Delta\\) es una perturbación aleatoria.\n\\(x_{ij}\\) se restringe a los límites del problema.\n\n\n\nCode\n# Mutación\ndef mutate(individual, bounds, mutation_rate, delta):\n    for i in range(len(individual)):\n        if np.random.rand() &lt; mutation_rate:\n            individual[i] += np.random.uniform(-delta, delta)\n            individual[i] = np.clip(individual[i], bounds[0], bounds[1])\n    return individual\n\n\n\nEvaluación y Sustitución\nLa nueva población es evaluada, y mediante el uso de elitismo, es posible conservar a los mejores individuos. El algoritmo continúa iterando con esta población actualizada, mejorando progresivamente la optimización de la función objetivo al incrementar el fitness general de la población.\n\n\nCode\n# Algoritmo completo\ndef genetic_algorithm(fitness_function, population_size, generations, mutation_rate, crossover_rate, dim, bounds, delta):\n    population = initialize_population(population_size, dim, bounds)\n    best_individual = None\n    trajectory = []\n    populations = []\n\n    for generation in range(generations):\n        populations.append(population.copy())\n        fitness = evaluate_fitness(population, fitness_function)\n        \n        if best_individual is None or np.min(fitness) &lt; fitness_function(best_individual):\n            best_individual = population[np.argmin(fitness)]\n        \n        # Guardar la mejor solución de esta generación\n        trajectory.append((*best_individual, fitness_function(best_individual)))\n        \n        # Selección\n        selected_population = tournament_selection(population, fitness)\n        \n        # Cruce y mutación\n        new_population = []\n        for i in range(0, len(selected_population), 2):\n            if i + 1 &lt; len(selected_population):\n                child1 = crossover(selected_population[i], selected_population[i+1], crossover_rate)\n                child2 = crossover(selected_population[i+1], selected_population[i], crossover_rate)\n                new_population.extend([child1, child2])\n            else:\n                new_population.append(selected_population[i])\n        \n        population = np.array([mutate(ind, bounds, mutation_rate, delta) for ind in new_population])\n    \n    # Convertir la trayectoria a DataFrame\n    \n    columns = [f'x{i+1}' for i in range(dim)] + ['f(x)']\n    df = pd.DataFrame(trajectory, columns=columns)\n    return best_individual, fitness_function(best_individual), df, populations\n\n\n\n\nFunción de RosenbrockFunción de RastriginFunción de SchwefelFunción de GriewankFunción Goldstein-PriceFunción de las seis jorobas de camello\n\n\n\\[f(\\mathbf{x}) = \\sum_{i=1}^{d-1} \\left[ 100(x_{i+1} - x_i^2)^2 + (x_i - 1)^2 \\right]\\]\n\n\n\n\\[f(\\mathbf{x}) = 10d + \\sum_{i=1}^{d} \\left[ x_i^2 - 10 \\cos(2\\pi x_i) \\right]\\]\n\n\n\n\\[ f(\\mathbf{x}) = 418.9829d - \\sum_{i=1}^{d} x_i \\sin(\\sqrt{|x_i|}) \\]\n\n\n\n\\[ f(\\mathbf{x}) = 1 + \\frac{1}{4000} \\sum_{i=1}^{d} x_i^2 - \\prod_{i=1}^{d} \\cos\\left(\\frac{x_i}{\\sqrt{i}}\\right) \\]\n\n\n\n\\[\n\\begin{align}\nf(x_1, x_2) = & \\left[1 + (x_1 + x_2 + 1)^2 (19 - 14x_1 + 3x_1^2 - 14x_2 + 6x_1x_2 + 3x_2^2)\\right] \\\\\n         & \\left[30 + (2x_1 - 3x_2)^2 (18 - 32x_1 + 12x_1^2 + 48x_2 - 36x_1x_2 + 27x_2^2)\\right]\n\\end{align}\n\\]\n\n\n\n\\[ f(x_1, x_2) = \\left(4 - 2.1x_1^2 + \\frac{x_1^4}{3}\\right)x_1^2 + x_1x_2 + \\left(-4 + 4x_2^2\\right)x_2^2 \\]\n\n\n\n\nLos algoritmos genéticos convergen hacia soluciones aproximadas, aunque no garantizan alcanzar el óptimo global. Sin embargo, suelen mostrar una rápida convergencia en pocas generaciones. Estos algoritmos buscan equilibrar dos objetivos clave: Exploración, que consiste en descubrir nuevas regiones del espacio de búsqueda, y Explotación, enfocada en refinar y mejorar las soluciones existentes.\nPara las simulaciones presentadas en los GIF, se utilizaron los siguientes parámetros: tamaño de población = 30, número de generaciones = 20, tasa de mutación = 0.5, y tasa de cruce = 0.5. El parámetro de mutación \\(\\delta\\) se ajusta según los límites de evaluación de las funciones objetivo, representando aproximadamente un 5% del rango de dichas funciones.\n\n\n2.2.3 Observaciones\nVentajas:\n\nNo requiere derivadas ni condiciones específicas en $$$f(x)$ .\nEs efectivo en espacios de búsqueda multimodales o no convexos.\nAdaptable a diversos problemas.\n\nDesventajas:\n\nPuede ser computacionalmente costoso.\nNo garantiza convergencia al óptimo global.\nRequiere ajuste cuidadoso de parámetros.\n\nComo se puede observar, en la mayoría de los casos de optimización para una unica corrida los puntos óptimos conergen a mínimos locales, lo que indica que los resultados óptimos pueden estar fuertemente influenciado por los valores iniciales de \\(x\\) o las condiciones de inicio de los algoritmos. Por esta razón, para evaluar el rendimiento y el comportamiento de los algoritmos en un entorno más general, se realizarán múltiples ejecuciones. En cada corrida, los algoritmos partirán de valores iniciales distintos generados aleatoriamente. Con esto se verá cuanto tardan los algoritmos en mejorar la evaluación de la función objetivo y cuales pueden ser algunos comentarios particulares a realizar. Los resultados se presentaran para los casos de 2 y 3 dimensiones de las funciones."
  },
  {
    "objectID": "posts/post-with-code/index.html#footnotes",
    "href": "posts/post-with-code/index.html#footnotes",
    "title": "Métodos de optimización heurística",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nEl fitness representa la aptitud o adecuación de una solución a un problema específico. En nuestro caso, representa la evaluación del individuo en la funcion objetivo.↩︎"
  },
  {
    "objectID": "posts/post-with-code/index.html#optimización-por-descenso-del-gradiente",
    "href": "posts/post-with-code/index.html#optimización-por-descenso-del-gradiente",
    "title": "Métodos de optimización heurística",
    "section": "2.1 Optimización por descenso del gradiente",
    "text": "2.1 Optimización por descenso del gradiente\nEl descenso del gradiente es un algoritmo de optimización iterativo que busca encontrar el mínimo local de una función diferenciable. La idea principal es moverse en la dirección opuesta al gradiente de la función en cada punto, ya que el gradiente apunta en la dirección de máximo crecimiento.\nSegun (Bishop 2006), para una función \\(f(x)\\), el algoritmo actualiza iterativamente el punto \\(x\\) usando la regla:\n\\[ x_{t+1} = x_t - \\eta \\nabla f(x_t) \\]\ndonde:\n\n\\(x_t\\) es el punto actual\n\\(\\eta\\) es la tasa de aprendizaje\n\\(\\nabla f(x_t)\\) es el gradiente de la función en \\(x_t\\)\n\nEl gradiente \\(\\nabla f\\) es un vector que contiene las derivadas parciales respecto a cada variable: \\[\\nabla f(x_1, x_2) = \\begin{bmatrix} \\frac{\\partial f}{\\partial x_1}, \\frac{\\partial f}{\\partial x_2} \\end{bmatrix}\\]\nEl gradiente \\(\\nabla f\\) se puede aproximar numéricamente usando diferencias finitas. (Bishop 2006) plantean que, se puede mejorar consideramblemente la presición del método usando diferencias centrales simétricas. En este caso, para una función \\(f(x_1, x_2)\\), las derivadas parciales se calculan como:\n\\[ \\frac{\\partial f}{\\partial x_1} \\approx \\frac{f(x_1 + h, x_2) - f(x_1 - h, x_2)}{2h} \\]\n\\[ \\frac{\\partial f}{\\partial x_2} \\approx \\frac{f(x_1, x_2 + h) - f(x_1, x_2 - h)}{2h} \\]\ndonde \\(h\\) es un pequeño incremento (típicamente \\(10^{-7}\\) o \\(10^{-8}\\)).\n\n\nCode\ndef partial_derivative(x0, func, i, h, *args):\n  e = np.zeros(len(x0))\n  e[i] = 1\n  return (func(x0+h*e, *args) - func(x0-h*e, *args))/(2*h)\n\ndef numerical_gradient(x0, func, h, *args):\n  gradient = np.zeros(len(x0))\n  for i in range(len(x0)):\n    gradient[i] = partial_derivative(x0, func, i, h, *args)\n  return gradient\n\ndef gradient_descent_num_dev_mult(x0, eta, func, h, max_iter, *args):\n  \"\"\"\n  Perform gradient descent with numerical derivatives for a multi-dimensional function.\n\n  Parameters:\n      x0 (array-like): Initial guess for the variables.\n      eta (float): Learning rate.\n      func (callable): Function to minimize.\n      h (float): Step size for numerical gradient calculation.\n      max_iter (int): Maximum number of iterations.\n      *args: Additional arguments for the function.\n\n  Returns:\n      result_df (pd.DataFrame): DataFrame with columns ['x1', 'x2', 'f(x1,x2)']\n                                containing the trajectory of points.\n  \"\"\"\n  x_old = np.array(x0)\n  x_hist = []  # List to store the history of x and f(x)\n\n  for i in range(max_iter):\n      # Calculate the gradient numerically\n      gradient = numerical_gradient(x_old, func, h, *args)\n\n      # Update x based on gradient descent rule\n      x_new = x_old - eta * gradient\n\n      # Append current x and function value to history\n      x_hist.append([x_old[0], x_old[1], func(x_old, *args)])\n\n      # Update x_old\n      x_old = x_new\n\n  # Add the final position and function value\n  x_hist.append([x_new[0], x_new[1], func(x_new, *args)])\n\n  # Convert history to a pandas DataFrame\n  result_df = pd.DataFrame(x_hist, columns=['x1', 'x2', 'f(x1,x2)'])\n\n  return result_df\n\n\nA continuación, se presentan las animaciones que ilustran la aplicación del descenso del gradiente en las seis funciones evaluadas. Los parámetros iniciales, la tasa de aprendizaje y el número de iteraciones del algoritmo fueron seleccionados cuidadosamente para optimizar la visualización del funcionamiento del método.Estos parámetros se detallan en las tablas a continuación.\n\nFunción de RosenbrockFunción de RastriginFunción de SchwefelFunción de GriewankFunción Goldstein-PriceFunción de las seis jorobas de camello\n\n\n\\[f(\\mathbf{x}) = \\sum_{i=1}^{d-1} \\left[ 100(x_{i+1} - x_i^2)^2 + (x_i - 1)^2 \\right]\\]\n\n\n\n\\(x_{1_0}\\)\n\\(x_{2_0}\\)\n\\(\\eta\\)\n\\(n\\)\n\n\n\n\n-1.5\n-1.7\n0.001\n30\n\n\n\n\n\n\n\\[f(\\mathbf{x}) = 10d + \\sum_{i=1}^{d} \\left[ x_i^2 - 10 \\cos(2\\pi x_i) \\right]\\]\n\n\n\n\\(x_{1_0}\\)\n\\(x_{2_0}\\)\n\\(\\eta\\)\n\\(n\\)\n\n\n\n\n-0.46\n0.46\n0.005\n30\n\n\n\n\n\n\n\\[ f(\\mathbf{x}) = 418.9829d - \\sum_{i=1}^{d} x_i \\sin(\\sqrt{|x_i|}) \\]\n\n\n\n\\(x_{1_0}\\)\n\\(x_{2_0}\\)\n\\(\\eta\\)\n\\(n\\)\n\n\n\n\n310\n310\n0.8\n30\n\n\n\n\n\n\n\\[ f(\\mathbf{x}) = 1 + \\frac{1}{4000} \\sum_{i=1}^{d} x_i^2 - \\prod_{i=1}^{d} \\cos\\left(\\frac{x_i}{\\sqrt{i}}\\right) \\]\n\n\n\n\\(x_{1_0}\\)\n\\(x_{2_0}\\)\n\\(\\eta\\)\n\\(n\\)\n\n\n\n\n-500\n500\n70\n33\n\n\n\n\n\n\n\\[\n\\begin{align}\nf(x_1, x_2) = & \\left[1 + (x_1 + x_2 + 1)^2 (19 - 14x_1 + 3x_1^2 - 14x_2 + 6x_1x_2 + 3x_2^2)\\right] \\\\\n         & \\left[30 + (2x_1 - 3x_2)^2 (18 - 32x_1 + 12x_1^2 + 48x_2 - 36x_1x_2 + 27x_2^2)\\right]\n\\end{align}\n\\]\n\n\n\n\\(x_{1_0}\\)\n\\(x_{2_0}\\)\n\\(\\eta\\)\n\\(n\\)\n\n\n\n\n0.5\n-1.5\n0.00005\n50\n\n\n\n\n\n\n\\[ f(x_1, x_2) = \\left(4 - 2.1x_1^2 + \\frac{x_1^4}{3}\\right)x_1^2 + x_1x_2 + \\left(-4 + 4x_2^2\\right)x_2^2 \\]\n\n\n\n\\(x_{1_0}\\)\n\\(x_{2_0}\\)\n\\(\\eta\\)\n\\(n\\)\n\n\n\n\n-1\n-1\n0.015\n33\n\n\n\n\n\n\n\nEl método del gradiente descendente puede imaginarse como una persona deslizándose por una colina representada por una función. El punto de inicio es el lugar desde donde comienza a deslizarse, y la tasa de aprendizaje actúa como la aceleración que controla la velocidad del deslizamiento en cada paso. Si esta aceleración es demasiado alta, puede ayudar a llegar más rápido al valle más bajo, pero también existe el riesgo de salir del camino o incluso terminar subiendo una colina debido a un impulso excesivo que sobrepasa el objetivo.\nPara garantizar que este método sea eficiente, es importante considerar lo siguiente:\n\nTasa de aprendizaje: Un valor demasiado grande puede causar divergencia, mientras que uno muy pequeño puede hacer que el proceso sea extremadamente lento.\nPunto inicial: La ubicación inicial afecta la trayectoria y la probabilidad de alcanzar el mínimo global.\nCriterio de parada: Es esencial definir cuándo detener el algoritmo, ya sea por alcanzar un número máximo de iteraciones o porque la mejora entre pasos sea insignificante (convergencia)."
  },
  {
    "objectID": "posts/post-with-code/index.html#optimización-de-partículas",
    "href": "posts/post-with-code/index.html#optimización-de-partículas",
    "title": "Métodos de optimización heurística",
    "section": "2.3 Optimización de partículas",
    "text": "2.3 Optimización de partículas\n\nFunción de RosenbrockFunción de RastriginFunción de SchwefelFunción de GriewankFunción Goldstein-PriceFunción de las seis jorobas de camello\n\n\n\\[f(\\mathbf{x}) = \\sum_{i=1}^{d-1} \\left[ 100(x_{i+1} - x_i^2)^2 + (x_i - 1)^2 \\right]\\]\n\n\n\n\\[f(\\mathbf{x}) = 10d + \\sum_{i=1}^{d} \\left[ x_i^2 - 10 \\cos(2\\pi x_i) \\right]\\]\n\n\n\n\\[ f(\\mathbf{x}) = 418.9829d - \\sum_{i=1}^{d} x_i \\sin(\\sqrt{|x_i|}) \\]\n\n\n\n\\[ f(\\mathbf{x}) = 1 + \\frac{1}{4000} \\sum_{i=1}^{d} x_i^2 - \\prod_{i=1}^{d} \\cos\\left(\\frac{x_i}{\\sqrt{i}}\\right) \\]\n\n\n\n\\[\n\\begin{align}\nf(x_1, x_2) = & \\left[1 + (x_1 + x_2 + 1)^2 (19 - 14x_1 + 3x_1^2 - 14x_2 + 6x_1x_2 + 3x_2^2)\\right] \\\\\n         & \\left[30 + (2x_1 - 3x_2)^2 (18 - 32x_1 + 12x_1^2 + 48x_2 - 36x_1x_2 + 27x_2^2)\\right]\n\\end{align}\n\\]\n\n\n\n\\[ f(x_1, x_2) = \\left(4 - 2.1x_1^2 + \\frac{x_1^4}{3}\\right)x_1^2 + x_1x_2 + \\left(-4 + 4x_2^2\\right)x_2^2 \\]"
  },
  {
    "objectID": "posts/post-with-code/index.html#optimización-diferencial",
    "href": "posts/post-with-code/index.html#optimización-diferencial",
    "title": "Métodos de optimización heurística",
    "section": "2.4 Optimización diferencial",
    "text": "2.4 Optimización diferencial"
  }
]